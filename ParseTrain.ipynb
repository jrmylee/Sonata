{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "sys.path.insert(1, \"/Users/jrmylee/Documents/Development/projects/mir/projects/sonata/models\")\n",
    "from preprocess import Preprocess\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"isophonics-beetles\" : {\n",
    "        \"mp3\": \"/Users/jrmylee/Documents/Development/projects/mir/datasets/isophonics/beetles_albums\",\n",
    "        \"labels\": \"/Users/jrmylee/Documents/Development/projects/mir/datasets/isophonics/beetles_annotations\"\n",
    "    },\n",
    "    \"isophonics-king\" : {\n",
    "        \"mp3\": \"/Users/jrmylee/Documents/Development/projects/mir/datasets/isophonics/carol_king_albums\",\n",
    "        \"labels\": \"/Users/jrmylee/Documents/Development/projects/mir/datasets/isophonics/carol_king_annotations\"\n",
    "    }\n",
    "}\n",
    "\n",
    "sample_rate = 22050\n",
    "hop_size= 2048\n",
    "window_size= 10\n",
    "song_hz= 22050\n",
    "p = Preprocess(sample_rate, hop_size, window_size, song_hz, None)\n",
    "\n",
    "king_albums = p.get_mp3(datasets['isophonics-king']['mp3'])\n",
    "king_labels = p.get_labels(datasets['isophonics-king']['labels'])\n",
    "beetles_albums = p.get_mp3(datasets['isophonics-beetles']['mp3'])\n",
    "beetles_labels = p.get_labels(datasets['isophonics-beetles']['labels'])\n",
    "\n",
    "data = [\n",
    "    (king_albums, king_labels),\n",
    "    (beetles_albums, beetles_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filename_to_title(filename):\n",
    "    name = re.sub(r'\\([^)]*\\)', '', filename)\n",
    "    new_name = \"\"\n",
    "    for character in name:\n",
    "        if character == '.':\n",
    "            break\n",
    "        if character.isalnum() and not character.isnumeric():\n",
    "            new_name += character\n",
    "    return new_name\n",
    "\n",
    "def path_to_album(path):\n",
    "    return os.path.basename(os.path.normpath(path))\n",
    "\n",
    "def generate_song_labels(label_album_path, labels_dict):\n",
    "    song_label_dict = {}\n",
    "    file_labels = labels_dict[label_album_path]\n",
    "    for file in file_labels:\n",
    "        if not file['filename'].endswith('.lab'):\n",
    "            continue\n",
    "        song_label_dict[file['title']] = []\n",
    "        with open(os.path.join(label_album_path, file['filename'])) as fp:\n",
    "            line = fp.readline()\n",
    "            while line:\n",
    "                tokens = line.split(' ')\n",
    "                if len(tokens) == 1: tokens = line.split('\\t')\n",
    "                onset = int(float(tokens[0]))\n",
    "                offset = int(float(tokens[1]))\n",
    "                chord = tokens[2][:len(tokens[2]) - 1]\n",
    "                song_label_dict[file['title']].append((onset, offset, chord))\n",
    "                line = fp.readline()\n",
    "    return song_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chords\n",
    "import random\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "c = chords.Chords()\n",
    "\n",
    "def augment_pitch(data, sr, label):\n",
    "    semitone = random.randint(1, 12)\n",
    "    aug_chord = c.shift(semitone, data, sr,label)\n",
    "    mfccs = librosa.feature.mfcc(y=aug_chord[0], sr=sr, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    \n",
    "    return mfccs_processed, aug_chord[1]\n",
    "\n",
    "def augment_stretched_noise(data, sr, label, noise=True, stretch=True):\n",
    "    composition = []\n",
    "    if noise:\n",
    "        composition.append(AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5))\n",
    "    if stretch:\n",
    "        composition.append(TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5))\n",
    "    augmenter = Compose(composition)\n",
    "    \n",
    "    aug_chord = augmenter(samples=data, sample_rate=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=aug_chord, sr=sr, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                         intervals = album_label_dict[album_title][song_title]\n",
    "#                         audio_slice, chords = get_chords_in_interval(data, intervals, (curr_sec, curr_sec + window_size))\n",
    "#                         mfccs = librosa.feature.mfcc(y=audio_slice, sr=sample_rate, n_mfcc=40)\n",
    "#                         mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "#                         curr_sec += hop_interval\n",
    "#                         features_list.append(mfccs_processed)\n",
    "#                         chords_list.append(chords)\n",
    "#                     for intervals in album_label_dict[album_title][song_title]:\n",
    "#                         start, end, chord = intervals[0], intervals[1], intervals[2]\n",
    "#                         if end > start:\n",
    "#                             start_index = librosa.time_to_samples(start)\n",
    "#                             end_index = librosa.time_to_samples(end)\n",
    "#                             audio_slice = data[int(start_index):int(end_index)]\n",
    "#                             if len(audio_slice) == 0:\n",
    "#                                 continue\n",
    "#                             mfccs = librosa.feature.mfcc(y=audio_slice, sr=sample_rate, n_mfcc=40)\n",
    "#                             mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "#                             features.append([mfccs_processed,  chord])\n",
    "\n",
    "#                             if chord != \"N\":\n",
    "#                                 pitched, pitched_label = augment_pitch(audio_slice, sample_rate, chord)\n",
    "#                                 features.append([pitched, pitched_label])\n",
    "\n",
    "#                             stretch_noised = augment_stretched_noise(audio_slice, sample_rate, chord)\n",
    "#                             features.append([stretch_noised, chord])\n",
    "                            \n",
    "#                             noised = augment_stretched_noise(audio_slice, sample_rate, chord, True, False)\n",
    "#                             features.append([noised, chord])\n",
    "                            \n",
    "#                             stretched = augment_stretched_noise(audio_slice, sample_rate, chord, False, True)\n",
    "#                             features.append([stretched, chord])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save, load\n",
    "save_dir = \"/Users/jrmylee/Documents/Development/projects/mir/projects/sonata/checkpoints/\"\n",
    "\n",
    "song_hz = 22050\n",
    "hop_size = 2048\n",
    "window_size = 10\n",
    "\n",
    "hop_interval = hop_size / song_hz #in seconds\n",
    "\n",
    "get_num_samples = lambda x : x / hop_interval\n",
    "\n",
    "def get_chords_in_interval(audio, chord_intervals, interval):\n",
    "    start_index = librosa.time_to_samples(interval[0])\n",
    "    end_index = librosa.time_to_samples(interval[1])\n",
    "    audio_slice = audio[int(start_index):int(end_index)]\n",
    "    ref_start, ref_end = interval[0], interval[1]\n",
    "    \n",
    "    chords = []\n",
    "    curr_interval = chord_intervals[0]\n",
    "    index = 0\n",
    "    while curr_interval[0] < ref_end and index < len(chord_intervals):\n",
    "        curr_interval = chord_intervals[index]\n",
    "        if curr_interval[1] > ref_start:\n",
    "            chords.append(curr_interval[2])\n",
    "        index += 1\n",
    "    return audio_slice, chords\n",
    "\n",
    "def get_chord_at_time(chord_intervals, time):\n",
    "    for interval in chord_intervals:\n",
    "        start, end = interval[0], interval[1]\n",
    "        if start <= time and end >= time:\n",
    "            return interval[2]\n",
    "    return \"C\"\n",
    "def get_mfcc(audio, sample_rate):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=144)\n",
    "    mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_processed\n",
    "def get_cqt(audio, sample_rate):\n",
    "    return librosa.cqt(audio, sr=sample_rate, n_bins=108, bins_per_octave=24, hop_length=2048)\n",
    "def get_start_end_indices(start_time, end_time):\n",
    "    start_index = librosa.time_to_samples(start_time)\n",
    "    end_index = librosa.time_to_samples(end_time)\n",
    "    return start_index, end_index\n",
    "\n",
    "def generate_features(albums_dict, album_label_dict):\n",
    "    features_list = []\n",
    "    chords_list = []\n",
    "    counter = 0\n",
    "    for album in albums_dict:\n",
    "        album_title = path_to_album(album)\n",
    "        for song in albums_dict[album]:\n",
    "            counter += 1\n",
    "            song_path = os.path.join(album, song[\"filename\"])\n",
    "            song_title = filename_to_title(song[\"filename\"])\n",
    "            song_save_path = save_dir + song_title + \"_data.pth\"\n",
    "            print(str(counter) +\"th song: \" + song_title)\n",
    "            if not os.path.exists(song_save_path):\n",
    "                if album_title in album_label_dict:\n",
    "                    if song_title in album_label_dict[album_title]:\n",
    "                        print(song_title + \" does not exist. Generating features.\")\n",
    "                        data, sr = librosa.load(song_path)\n",
    "                        curr_start_time = 0\n",
    "                        total_duration = librosa.get_duration(y=data, sr=sr)\n",
    "                        num_samples = get_num_samples(total_duration)\n",
    "                        intervals = album_label_dict[album_title][song_title]\n",
    "                        song_features = []\n",
    "                        song_chords = []\n",
    "                        while curr_start_time + window_size < total_duration:\n",
    "                            curr_sec = curr_start_time\n",
    "                            curr_chords = [] # chords in the time frame\n",
    "                            while curr_sec < curr_start_time + window_size:\n",
    "                                chord = get_chord_at_time(intervals, curr_sec)\n",
    "                                curr_sec += hop_interval\n",
    "                                curr_chords.append(chord)\n",
    "                            start_index, end_index = get_start_end_indices(curr_start_time, curr_start_time+window_size)\n",
    "                            audio_slice = data[int(start_index):int(end_index)]\n",
    "                            curr_features = get_cqt(audio_slice, sr)\n",
    "                            song_features.append(curr_features)\n",
    "                            song_chords.append(curr_chords)\n",
    "                            curr_start_time += hop_interval\n",
    "                        print(\"saving song: \" + song_title)\n",
    "                        save_obj = {\n",
    "                            \"song\": song_title,\n",
    "                            \"album\": album_title,\n",
    "                            \"features\": song_features,\n",
    "                            \"chords\": song_chords\n",
    "                        }\n",
    "                        save(save_obj, song_save_path)\n",
    "                        features_list.extend(song_features)\n",
    "                        chords_list.extend(song_chords)\n",
    "            else:\n",
    "                print(song_title + \" exists.  Fetching cached.\")\n",
    "                cached = load(song_save_path)\n",
    "                features_list.extend(cached['features'])\n",
    "                chords_list.extend(cached['chords'])\n",
    "                            \n",
    "    return features_list, chords_list\n",
    "\n",
    "def save_to_file(fname, arr):\n",
    "    a = np.array(arr)\n",
    "    np.savetxt(fname, a, fmt='%d')\n",
    "def load_from_file(fname):\n",
    "    try:\n",
    "        b = np.loadtxt(fname, dtype=int)\n",
    "        return b\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th song: SmackwaterJack\n",
      "2th song: HomeAgain\n",
      "HomeAgain exists.  Fetching cached.\n",
      "3th song: ANaturalWoman\n",
      "4th song: IFeelTheEarthMove\n",
      "IFeelTheEarthMove exists.  Fetching cached.\n",
      "5th song: Tapestry\n",
      "6th song: Beautiful\n",
      "Beautiful exists.  Fetching cached.\n",
      "7th song: WayOverYonder\n",
      "WayOverYonder exists.  Fetching cached.\n",
      "8th song: YouveGotAFriend\n",
      "YouveGotAFriend exists.  Fetching cached.\n",
      "9th song: SmackwaterJack\n",
      "10th song: ItsTooLate\n",
      "ItsTooLate exists.  Fetching cached.\n",
      "11th song: WillYouLoveMeTomorrow\n",
      "12th song: WhereYouLead\n",
      "13th song: SoFarAway\n",
      "SoFarAway exists.  Fetching cached.\n",
      "14th song: OutInTheCold\n",
      "1th song: Flying\n",
      "Flying exists.  Fetching cached.\n",
      "2th song: IAmTheWalrus\n",
      "IAmTheWalrus exists.  Fetching cached.\n",
      "3th song: MagicalMysteryTour\n",
      "MagicalMysteryTour exists.  Fetching cached.\n",
      "4th song: TheFoolOnTheHill\n",
      "TheFoolOnTheHill exists.  Fetching cached.\n",
      "5th song: IAmTheWalrusRecordingSession\n",
      "6th song: IAmtheWalrus\n",
      "IAmtheWalrus exists.  Fetching cached.\n",
      "7th song: IAmTheWalrus\n",
      "IAmTheWalrus exists.  Fetching cached.\n",
      "8th song: Flying\n",
      "Flying exists.  Fetching cached.\n",
      "9th song: AllYouNeedIsLove\n",
      "AllYouNeedIsLove exists.  Fetching cached.\n",
      "10th song: YourMotherShouldKnow\n",
      "YourMotherShouldKnow exists.  Fetching cached.\n",
      "11th song: IllBeBack\n",
      "IllBeBack exists.  Fetching cached.\n",
      "12th song: Matchbox\n",
      "13th song: AndILoveHer\n",
      "AndILoveHer exists.  Fetching cached.\n",
      "14th song: AndILoveHer\n",
      "AndILoveHer exists.  Fetching cached.\n",
      "15th song: CantBuyMeLove\n",
      "CantBuyMeLove exists.  Fetching cached.\n",
      "16th song: IGotaWoman\n",
      "17th song: LongTallSally\n",
      "18th song: SlowDown\n",
      "19th song: IfIFell\n",
      "IfIFell exists.  Fetching cached.\n",
      "20th song: YouCantDoThat\n",
      "YouCantDoThat exists.  Fetching cached.\n",
      "21th song: AHardDaysNight\n",
      "AHardDaysNight exists.  Fetching cached.\n",
      "22th song: LongTallSally\n",
      "23th song: LeaveMyKittenAlone\n",
      "24th song: YouKnowWhatToDo\n",
      "25th song: LongTallSally\n",
      "26th song: WhenIGetHome\n",
      "WhenIGetHome exists.  Fetching cached.\n",
      "27th song: TellMeWhy\n",
      "TellMeWhy exists.  Fetching cached.\n",
      "28th song: IllBeBack\n",
      "IllBeBack exists.  Fetching cached.\n",
      "29th song: ImHappyJusttoDancewithYou\n",
      "30th song: Matchbox\n",
      "31th song: IllBeBack\n",
      "IllBeBack exists.  Fetching cached.\n",
      "32th song: IfIFell\n",
      "IfIFell exists.  Fetching cached.\n",
      "33th song: ThingsWeSaidToday\n",
      "ThingsWeSaidToday exists.  Fetching cached.\n",
      "34th song: LetItBe\n",
      "LetItBe exists.  Fetching cached.\n",
      "35th song: AllThingsMustPass\n",
      "36th song: MyImagination\n",
      "37th song: IMeMine\n",
      "IMeMine exists.  Fetching cached.\n",
      "38th song: NoPakistanis\n",
      "39th song: DontLetMeDown\n",
      "40th song: TheLongandWindingRoad\n",
      "TheLongandWindingRoad exists.  Fetching cached.\n",
      "41th song: AllIWantisYou\n",
      "42th song: LetItBe\n",
      "LetItBe exists.  Fetching cached.\n",
      "43th song: TeaMoneyandWine\n",
      "44th song: WatchingRainbows\n",
      "45th song: GetBack\n",
      "GetBack exists.  Fetching cached.\n",
      "46th song: ForYouBlue\n",
      "ForYouBlue exists.  Fetching cached.\n",
      "47th song: ComeAndGetIt\n",
      "48th song: TheLongAndWindingRoad\n",
      "TheLongAndWindingRoad exists.  Fetching cached.\n",
      "49th song: TeddyBoy\n",
      "50th song: DigaPony\n",
      "DigaPony exists.  Fetching cached.\n",
      "51th song: Madman\n",
      "52th song: RipItUpShakeRattleandRollBlueSuedeShoes\n",
      "53th song: OneAfter\n",
      "OneAfter exists.  Fetching cached.\n",
      "54th song: RiverRhine\n",
      "55th song: ShakingInTheSixties\n",
      "56th song: TwoofUs\n",
      "TwoofUs exists.  Fetching cached.\n",
      "57th song: GehRaus\n",
      "58th song: DigAPony\n",
      "DigAPony exists.  Fetching cached.\n",
      "59th song: MailmanBringMeNoMoreBlues\n",
      "60th song: ThePalaceoftheKingoftheBirds\n",
      "61th song: ILostMyLittleGirl\n",
      "62th song: BillyBeatleBoogie\n",
      "63th song: IToldYouBeforeGetOutOfMyDoor\n",
      "64th song: Goodbye\n",
      "65th song: IveGotAFeeling\n",
      "IveGotAFeeling exists.  Fetching cached.\n",
      "66th song: IMeMine\n",
      "IMeMine exists.  Fetching cached.\n",
      "67th song: GetBack\n",
      "GetBack exists.  Fetching cached.\n",
      "68th song: QuickJam\n",
      "69th song: GetBack\n",
      "GetBack exists.  Fetching cached.\n",
      "70th song: JazzPiano\n",
      "71th song: ImDown\n",
      "72th song: AnotherGirl\n",
      "AnotherGirl exists.  Fetching cached.\n",
      "73th song: IfYouveGotTrouble\n",
      "74th song: YouveGottoHideYourLoveAway\n",
      "75th song: TheNightBefore\n",
      "TheNightBefore exists.  Fetching cached.\n",
      "76th song: YesItIs\n",
      "77th song: Yesterday\n",
      "Yesterday exists.  Fetching cached.\n",
      "78th song: ItsOnlyLove\n",
      "ItsOnlyLove exists.  Fetching cached.\n",
      "79th song: ThatMeansALot\n",
      "80th song: ImDown\n",
      "81th song: Yesterday\n",
      "Yesterday exists.  Fetching cached.\n",
      "82th song: TicketToRide\n",
      "TicketToRide exists.  Fetching cached.\n",
      "83th song: RingoProfile\n",
      "84th song: Michelle\n",
      "Michelle exists.  Fetching cached.\n",
      "85th song: JohnProfile\n",
      "86th song: NorwegianWood\n",
      "NorwegianWood exists.  Fetching cached.\n",
      "87th song: RunforYourLife\n",
      "88th song: Girl\n",
      "Girl exists.  Fetching cached.\n",
      "89th song: IfINeededSomeone\n",
      "IfINeededSomeone exists.  Fetching cached.\n",
      "90th song: BarOriginal\n",
      "91th song: ShesAWoman\n",
      "92th song: HoneyDont\n",
      "HoneyDont exists.  Fetching cached.\n",
      "93th song: KansasCityHeyHeyHeyHey\n",
      "KansasCityHeyHeyHeyHey exists.  Fetching cached.\n",
      "94th song: IllFollowtheSun\n",
      "IllFollowtheSun exists.  Fetching cached.\n",
      "95th song: IFeelFine\n",
      "96th song: EverybodysTryingToBeMyBaby\n",
      "97th song: NoReply\n",
      "NoReply exists.  Fetching cached.\n",
      "98th song: Mr\n",
      "Mr exists.  Fetching cached.\n",
      "99th song: HoneyDont\n",
      "HoneyDont exists.  Fetching cached.\n",
      "100th song: RockAndRollMusic\n",
      "101th song: IFeelFine\n",
      "102th song: IFeelFine\n",
      "103th song: TheBeatlesEverybodysTryingToBeMyBaby\n",
      "104th song: SavoyTruffle\n",
      "105th song: TheBeatlesChristmasRecord\n",
      "106th song: HelterSkelterGoneTomorrowHereToday\n",
      "107th song: NotGuilty\n",
      "108th song: WhileMyGuitarGentlyWeeps\n",
      "109th song: WhileMyGuitarGentlyWeeps\n",
      "110th song: HeyJude\n",
      "111th song: WhyDontWeDoItInTheRoad\n",
      "112th song: HelterSkelter\n",
      "113th song: WhyDontWeDoItintheRoad\n",
      "114th song: WhatsTheNewMaryJane\n",
      "115th song: StepInsideLoveLosParanoias\n",
      "116th song: Blackbird\n",
      "117th song: TheContinuingStoryOfBungalowBill\n",
      "118th song: GoodNight\n",
      "119th song: LadyMadonna\n",
      "120th song: HelterSkelter\n",
      "121th song: Revolution\n",
      "122th song: Piggies\n",
      "123th song: BackintheU\n",
      "124th song: SourMilkSea\n",
      "125th song: Circles\n",
      "126th song: IWill\n",
      "127th song: SpiritualRegeneration\n",
      "128th song: Blackbird\n",
      "129th song: GlassOnion\n",
      "130th song: HelterSkelter\n",
      "131th song: RevolutionI\n",
      "132th song: GlassOnion\n",
      "133th song: TheContinuingStoryofBungalowBill\n",
      "134th song: CryBabyCry\n",
      "135th song: ChildofNature\n",
      "136th song: CryBabyCry\n",
      "137th song: TheInnerLight\n",
      "138th song: Heather\n",
      "139th song: RockyRaccoon\n",
      "140th song: ImSoTired\n",
      "141th song: ImSoTired\n",
      "142th song: Julia\n",
      "143th song: RockyRaccoon\n",
      "144th song: WithinYouWithoutYou\n",
      "WithinYouWithoutYou exists.  Fetching cached.\n",
      "145th song: Sgt\n",
      "Sgt exists.  Fetching cached.\n",
      "146th song: GoodMorningGoodMorning\n",
      "GoodMorningGoodMorning exists.  Fetching cached.\n",
      "147th song: GettingBetter\n",
      "GettingBetter exists.  Fetching cached.\n",
      "148th song: ADayIntheLife\n",
      "ADayIntheLife exists.  Fetching cached.\n",
      "149th song: WithALittleHelpFromMyFriends\n",
      "WithALittleHelpFromMyFriends exists.  Fetching cached.\n",
      "150th song: FixingAHole\n",
      "FixingAHole exists.  Fetching cached.\n",
      "151th song: ShesLeavingHome\n",
      "ShesLeavingHome exists.  Fetching cached.\n",
      "152th song: LucyIntheSkyWithDiamonds\n",
      "LucyIntheSkyWithDiamonds exists.  Fetching cached.\n",
      "153th song: ADayInTheLife\n",
      "ADayInTheLife exists.  Fetching cached.\n",
      "154th song: Sgt\n",
      "Sgt exists.  Fetching cached.\n",
      "155th song: GoodMorningGoodMorning\n",
      "GoodMorningGoodMorning exists.  Fetching cached.\n",
      "156th song: WithALittleHelpFromMyFriends\n",
      "WithALittleHelpFromMyFriends exists.  Fetching cached.\n",
      "157th song: WithinYouWithoutYou\n",
      "WithinYouWithoutYou exists.  Fetching cached.\n",
      "158th song: LucyInTheSkyWithDiamonds\n",
      "LucyInTheSkyWithDiamonds exists.  Fetching cached.\n",
      "159th song: ShesLeavingHome\n",
      "ShesLeavingHome exists.  Fetching cached.\n",
      "160th song: PennyLane\n",
      "161th song: LucyInTheSkyWithDiamonds\n",
      "LucyInTheSkyWithDiamonds exists.  Fetching cached.\n",
      "162th song: GoodMorningGoodMorning\n",
      "GoodMorningGoodMorning exists.  Fetching cached.\n",
      "163th song: BeingfortheBenefitofMrKiteIWantYou\n",
      "164th song: ChristmasTime\n",
      "165th song: StrawberryFieldsForever\n",
      "166th song: Sgt\n",
      "Sgt exists.  Fetching cached.\n",
      "167th song: WithinYouWithoutYou\n",
      "WithinYouWithoutYou exists.  Fetching cached.\n",
      "168th song: StrawberryFieldsForever\n",
      "169th song: StrawberryFieldsForever\n",
      "170th song: BeingForTheBenefitOfMr\n",
      "BeingForTheBenefitOfMr exists.  Fetching cached.\n",
      "171th song: LovelyRita\n",
      "LovelyRita exists.  Fetching cached.\n",
      "172th song: LovelyRita\n",
      "LovelyRita exists.  Fetching cached.\n",
      "173th song: ShesLeavingHome\n",
      "ShesLeavingHome exists.  Fetching cached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174th song: IWannaBeYourMan\n",
      "IWannaBeYourMan exists.  Fetching cached.\n",
      "175th song: HappyBirthdayDearSaturdayClub\n",
      "176th song: ThisBoy\n",
      "177th song: Money\n",
      "Money exists.  Fetching cached.\n",
      "178th song: Clarabella\n",
      "179th song: DevilInHerHeart\n",
      "DevilInHerHeart exists.  Fetching cached.\n",
      "180th song: LendMeYourComb\n",
      "181th song: SheLovesYou\n",
      "182th song: TheHippyHippyShake\n",
      "183th song: YouReallyGotAHoldOnMe\n",
      "YouReallyGotAHoldOnMe exists.  Fetching cached.\n",
      "184th song: AllMyLoving\n",
      "AllMyLoving exists.  Fetching cached.\n",
      "185th song: Money\n",
      "Money exists.  Fetching cached.\n",
      "186th song: TillThereWasYou\n",
      "TillThereWasYou exists.  Fetching cached.\n",
      "187th song: IWanttoHoldYourHand\n",
      "188th song: YouReallyGotAHoldOnMe\n",
      "YouReallyGotAHoldOnMe exists.  Fetching cached.\n",
      "189th song: RollOverBeethoven\n",
      "RollOverBeethoven exists.  Fetching cached.\n",
      "190th song: HoldMeTight\n",
      "HoldMeTight exists.  Fetching cached.\n",
      "191th song: DontBotherMe\n",
      "DontBotherMe exists.  Fetching cached.\n",
      "192th song: Lucille\n",
      "193th song: ThisBoy\n",
      "194th song: ThisBoy\n",
      "195th song: WordsofLove\n",
      "196th song: PleaseMisterPostman\n",
      "PleaseMisterPostman exists.  Fetching cached.\n",
      "197th song: DontEverChange\n",
      "198th song: IWannaBeYourMan\n",
      "IWannaBeYourMan exists.  Fetching cached.\n",
      "199th song: IWantToHoldYourHand\n",
      "200th song: SheLovesYou\n",
      "201th song: SureToFall\n",
      "202th song: ToKnowHerIsToLoveHer\n",
      "203th song: SheLovesYou\n",
      "204th song: LittleChild\n",
      "LittleChild exists.  Fetching cached.\n",
      "205th song: TooMuchMonkeyBusiness\n",
      "206th song: AllMyLoving\n",
      "AllMyLoving exists.  Fetching cached.\n",
      "207th song: SheLovesYou\n",
      "208th song: ItWontBeLong\n",
      "ItWontBeLong exists.  Fetching cached.\n",
      "209th song: SoHowCome\n",
      "210th song: PleaseMisterPostman\n",
      "PleaseMisterPostman exists.  Fetching cached.\n",
      "211th song: MeanMr\n",
      "212th song: MeanMr\n",
      "213th song: FreeAsABird\n",
      "214th song: HereComestheSunTheInnerLight\n",
      "215th song: Because\n",
      "Because exists.  Fetching cached.\n",
      "216th song: ComeTogether\n",
      "ComeTogether exists.  Fetching cached.\n",
      "217th song: PolythenePam\n",
      "PolythenePam exists.  Fetching cached.\n",
      "218th song: OctopussGarden\n",
      "OctopussGarden exists.  Fetching cached.\n",
      "219th song: IWantYou\n",
      "IWantYou exists.  Fetching cached.\n",
      "220th song: OctopussGarden\n",
      "OctopussGarden exists.  Fetching cached.\n",
      "221th song: SomethingBlueJayWay\n",
      "222th song: Because\n",
      "Because exists.  Fetching cached.\n",
      "223th song: SheCameInThroughTheBathroom\n",
      "224th song: ThatllBeTheDay\n",
      "225th song: MaggieMae\n",
      "226th song: MovinNGroovin\n",
      "227th song: Catswalk\n",
      "228th song: Wildcat\n",
      "229th song: TheSheikOfAraby\n",
      "230th song: HallelujahILoveHerSo\n",
      "231th song: OneAfter\n",
      "OneAfter exists.  Fetching cached.\n",
      "232th song: Cayenne\n",
      "233th song: DeccaAudition\n",
      "234th song: TakeGoodCareOfMyBaby\n",
      "235th song: ThreeCoolCats\n",
      "236th song: ImTalkingAboutYou\n",
      "237th song: AskMeWhy\n",
      "AskMeWhy exists.  Fetching cached.\n",
      "238th song: DoYouWanttoKnowaSecret\n",
      "239th song: IGotToFindMyBaby\n",
      "240th song: Chains\n",
      "Chains exists.  Fetching cached.\n",
      "241th song: AskMeWhy\n",
      "AskMeWhy exists.  Fetching cached.\n",
      "242th song: FromMeToYou\n",
      "243th song: IllBeOnMyWay\n",
      "244th song: LoveMeDo\n",
      "LoveMeDo exists.  Fetching cached.\n",
      "245th song: GoodDaySunshine\n",
      "246th song: TomorrowNeverKnows\n",
      "247th song: EleanorRigbyJulia\n",
      "248th song: ImOnlySleeping\n",
      "249th song: DoctorRobert\n",
      "250th song: TheBeatlesFourthChristmasRecordPantomimeEverywhereItsChristmas\n",
      "251th song: Taxman\n",
      "252th song: Taxman\n",
      "253th song: PaperbackWriter\n",
      "254th song: AndYourBirdCanSing\n"
     ]
    }
   ],
   "source": [
    "features, chords = [], []\n",
    "for d in data:\n",
    "    album_label_dict = {}\n",
    "    albums_dict = d[0]\n",
    "    l_dict = d[1]\n",
    "    for label_path in l_dict:\n",
    "        song_label_dict = generate_song_labels(label_path, l_dict)\n",
    "        album_title = path_to_album(label_path)\n",
    "        album_label_dict[album_title] = song_label_dict\n",
    "    f, c = generate_features(albums_dict, album_label_dict)\n",
    "    features.extend(f)\n",
    "    chords.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(features, chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/jrmylee/Documents/Development/projects/mir/repos/BTC-ISMIR19')\n",
    "from btc_model import *\n",
    "from torch import optim\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "config = {\n",
    "    'feature_size' : 108,\n",
    "    'timestep' : 108,\n",
    "    'num_chords' : 133,\n",
    "    'input_dropout' : 0.2,\n",
    "    'layer_dropout' : 0.2,\n",
    "    'attention_dropout' : 0.2,\n",
    "    'relu_dropout' : 0.2,\n",
    "    'num_layers' : 8,\n",
    "    'num_heads' : 4,\n",
    "    'hidden_size' : 128,\n",
    "    'total_key_depth' : 128,\n",
    "    'total_value_depth' : 128,\n",
    "    'filter_size' : 128,\n",
    "    'loss' : 'ce',\n",
    "    'probs_out' : False\n",
    "}\n",
    "model = BTC_model(config=config).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import is_tensor, tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        le = LabelEncoder()\n",
    "        d = [[None, None] for i in range(len(dataset))]\n",
    "        for i in range(len(dataset)):\n",
    "            d[i][0] = dataset[i][0]\n",
    "            d[i][1] = le.fit_transform(dataset[i][1])\n",
    "        self.dataset = d\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        if is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = { 'audio': self.dataset[idx][0], 'chord': self.dataset[idx][1]}\n",
    "        return sample\n",
    "\n",
    "def _collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    features = []\n",
    "    chords = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sample = batch[i]\n",
    "        feature = sample['audio']\n",
    "        chord = sample['chord']\n",
    "        features.append(feature)\n",
    "        chords.append(chord)\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    chords = torch.tensor(chords, dtype=torch.int64)\n",
    "\n",
    "    return features, chords\n",
    "\n",
    "class ChordDataloader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ChordDataloader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = _collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      " Training...\n",
      " Number of samples remaining: 161987\n",
      " Number of samples remaining: 160707\n",
      " Number of samples remaining: 159427\n",
      " Number of samples remaining: 158147\n",
      " Number of samples remaining: 156867\n",
      " Number of samples remaining: 155587\n",
      " Number of samples remaining: 154307\n",
      " Number of samples remaining: 153027\n",
      " Number of samples remaining: 151747\n",
      " Number of samples remaining: 150467\n",
      "  batch: 99\n",
      "[1,     2] loss: 2.320\n",
      " Number of samples remaining: 149187\n",
      " Number of samples remaining: 147907\n",
      " Number of samples remaining: 146627\n",
      " Number of samples remaining: 145347\n",
      " Number of samples remaining: 144067\n",
      " Number of samples remaining: 142787\n",
      " Number of samples remaining: 141507\n",
      " Number of samples remaining: 140227\n",
      " Number of samples remaining: 138947\n",
      " Number of samples remaining: 137667\n",
      "  batch: 199\n",
      "[1,     2] loss: 1.715\n",
      " Number of samples remaining: 136387\n",
      " Number of samples remaining: 135107\n",
      " Number of samples remaining: 133827\n",
      " Number of samples remaining: 132547\n",
      " Number of samples remaining: 131267\n",
      " Number of samples remaining: 129987\n",
      " Number of samples remaining: 128707\n",
      " Number of samples remaining: 127427\n",
      " Number of samples remaining: 126147\n",
      " Number of samples remaining: 124867\n",
      "  batch: 299\n",
      "[1,     2] loss: 1.641\n",
      " Number of samples remaining: 123587\n",
      " Number of samples remaining: 122307\n",
      " Number of samples remaining: 121027\n",
      " Number of samples remaining: 119747\n",
      " Number of samples remaining: 118467\n",
      " Number of samples remaining: 117187\n",
      " Number of samples remaining: 115907\n",
      " Number of samples remaining: 114627\n",
      " Number of samples remaining: 113347\n",
      " Number of samples remaining: 112067\n",
      "  batch: 399\n",
      "[1,     2] loss: 1.613\n",
      " Number of samples remaining: 110787\n",
      " Number of samples remaining: 109507\n",
      " Number of samples remaining: 108227\n",
      " Number of samples remaining: 106947\n",
      " Number of samples remaining: 105667\n",
      " Number of samples remaining: 104387\n",
      " Number of samples remaining: 103107\n",
      " Number of samples remaining: 101827\n",
      " Number of samples remaining: 100547\n",
      " Number of samples remaining: 99267\n",
      "  batch: 499\n",
      "[1,     2] loss: 1.598\n",
      " Number of samples remaining: 97987\n",
      " Number of samples remaining: 96707\n",
      " Number of samples remaining: 95427\n",
      " Number of samples remaining: 94147\n",
      " Number of samples remaining: 92867\n",
      " Number of samples remaining: 91587\n",
      " Number of samples remaining: 90307\n",
      " Number of samples remaining: 89027\n",
      " Number of samples remaining: 87747\n",
      " Number of samples remaining: 86467\n",
      "  batch: 599\n",
      "[1,     2] loss: 1.605\n",
      " Number of samples remaining: 85187\n",
      " Number of samples remaining: 83907\n",
      " Number of samples remaining: 82627\n",
      " Number of samples remaining: 81347\n",
      " Number of samples remaining: 80067\n",
      " Number of samples remaining: 78787\n",
      " Number of samples remaining: 77507\n",
      " Number of samples remaining: 76227\n",
      " Number of samples remaining: 74947\n",
      " Number of samples remaining: 73667\n",
      "  batch: 699\n",
      "[1,     2] loss: 1.599\n",
      " Number of samples remaining: 72387\n",
      " Number of samples remaining: 71107\n",
      " Number of samples remaining: 69827\n",
      " Number of samples remaining: 68547\n",
      " Number of samples remaining: 67267\n",
      " Number of samples remaining: 65987\n",
      " Number of samples remaining: 64707\n",
      " Number of samples remaining: 63427\n",
      " Number of samples remaining: 62147\n",
      " Number of samples remaining: 60867\n",
      "  batch: 799\n",
      "[1,     2] loss: 1.595\n",
      " Number of samples remaining: 59587\n",
      " Number of samples remaining: 58307\n",
      " Number of samples remaining: 57027\n",
      " Number of samples remaining: 55747\n",
      " Number of samples remaining: 54467\n",
      " Number of samples remaining: 53187\n",
      " Number of samples remaining: 51907\n",
      " Number of samples remaining: 50627\n",
      " Number of samples remaining: 49347\n",
      " Number of samples remaining: 48067\n",
      "  batch: 899\n",
      "[1,     2] loss: 1.595\n",
      " Number of samples remaining: 46787\n",
      " Number of samples remaining: 45507\n",
      " Number of samples remaining: 44227\n",
      " Number of samples remaining: 42947\n",
      " Number of samples remaining: 41667\n",
      " Number of samples remaining: 40387\n",
      " Number of samples remaining: 39107\n",
      " Number of samples remaining: 37827\n",
      " Number of samples remaining: 36547\n",
      " Number of samples remaining: 35267\n",
      "  batch: 999\n",
      "[1,     2] loss: 1.595\n",
      " Number of samples remaining: 33987\n",
      " Number of samples remaining: 32707\n",
      " Number of samples remaining: 31427\n",
      " Number of samples remaining: 30147\n",
      " Number of samples remaining: 28867\n",
      " Number of samples remaining: 27587\n",
      " Number of samples remaining: 26307\n",
      " Number of samples remaining: 25027\n",
      " Number of samples remaining: 23747\n",
      " Number of samples remaining: 22467\n",
      "  batch: 1099\n",
      "[1,     2] loss: 1.575\n",
      " Number of samples remaining: 21187\n",
      " Number of samples remaining: 19907\n",
      " Number of samples remaining: 18627\n",
      " Number of samples remaining: 17347\n",
      " Number of samples remaining: 16067\n",
      " Number of samples remaining: 14787\n",
      " Number of samples remaining: 13507\n",
      " Number of samples remaining: 12227\n",
      " Number of samples remaining: 10947\n",
      " Number of samples remaining: 9667\n",
      "  batch: 1199\n",
      "[1,     2] loss: 1.579\n",
      " Number of samples remaining: 8387\n",
      " Number of samples remaining: 7107\n",
      " Number of samples remaining: 5827\n",
      " Number of samples remaining: 4547\n",
      " Number of samples remaining: 3267\n",
      " Number of samples remaining: 1987\n",
      " Number of samples remaining: 707\n",
      "Done training!  Validation:\n",
      "Validation result: %38.55721393034826\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_set, test_set = ChordDataset(train_dataset), ChordDataset(test_dataset) \n",
    "train_dataloader = ChordDataloader(train_set, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_dataloader = ChordDataloader(test_set, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "#     Training\n",
    "    print(\" Training...\")\n",
    "    remaining = train_size\n",
    "    for i_batch, data in enumerate(train_dataloader):\n",
    "        if i_batch % 10 == 0:\n",
    "            print(\" Number of samples remaining: \" + str(remaining))\n",
    "        features, chords = data\n",
    "        features.requires_grad = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        features = features.to(device)\n",
    "        chords = chords.to(device)\n",
    "        # Train\n",
    "        prediction, total_loss, weights, second = model(features, chords)\n",
    "        \n",
    "        running_loss += total_loss.item()\n",
    "        \n",
    "        if i_batch % 100 == 99:\n",
    "            print(\"  batch: \" + str(i_batch))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        remaining -= 128\n",
    "# Validation\n",
    "    print(\"Done training!  Validation:\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            val_features, val_chords = data\n",
    "            val_features.requires_grad = True\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            val_features = features.to(device)\n",
    "            val_chords = chords.to(device)\n",
    "            # Train\n",
    "            val_prediction, val_loss, weights, val_second = model(val_features, val_chords)\n",
    "            total += val_prediction.size(0)\n",
    "            correct += (val_prediction.view(val_chords.size(0), 108) == val_chords).sum().item()\n",
    "        result = (100 * correct / total)\n",
    "        print(\"Validation result: %\" + str(result) )\n",
    "    file_name = \"model-epoch-\" + str(epoch)\n",
    "    model_obj = {\"model\": model.state_dict(), 'optimizer': optimizer.state_dict(), \"epoch\": epoch}\n",
    "    torch.save(model_obj, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jrmylee/Documents/Development/projects/mir/projects/sonata/checkpoints/'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(zip(flatten_features, chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "print(len(a[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
